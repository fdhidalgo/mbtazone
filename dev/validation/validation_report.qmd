---
title: "MBTA Communities Act R Package Validation Report"
subtitle: "Systematic Comparison of mbtazone Package vs Excel Compliance Models"
author: "Daniel Hidalgo"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    code-fold: true
    code-summary: "Show code"
    theme: cosmo
    fig-width: 10
    fig-height: 6
    df-print: paged
editor: source
self-contained-math: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(data.table)
library(ggplot2)
library(knitr)
library(DT)

# Load validation results
validation_results <- readRDS("validation_results.rds")
method1_results <- validation_results$method1
method2_results <- validation_results$method2

# Helper function for formatting
format_pct <- function(x) {
  sprintf("%.1f%%", x)
}

format_number <- function(x) {
  format(x, big.mark = ",", scientific = FALSE)
}
```

# Executive Summary

This report presents a comprehensive validation of the `mbtazone` R package against Excel compliance models for the Massachusetts MBTA Communities Act. The validation encompasses **`r nrow(method1_results)` municipalities** across two validation methodologies.

## Key Findings

```{r summary-stats, echo=FALSE}
# Method 1 statistics
m1_success <- method1_results[success == TRUE]
m1_success_rate <- nrow(m1_success) / nrow(method1_results) * 100

# Categorize results
exact_match <- nrow(m1_success[unit_pct_diff == 0])
minimal <- nrow(m1_success[unit_pct_diff != 0 & abs(unit_pct_diff) < 2])
small <- nrow(m1_success[abs(unit_pct_diff) >= 2 & abs(unit_pct_diff) < 5])
medium <- nrow(m1_success[abs(unit_pct_diff) >= 5 & abs(unit_pct_diff) < 25])
large <- nrow(m1_success[abs(unit_pct_diff) >= 25])

# Method 2 statistics
m2_success <- method2_results[success == TRUE]
m2_success_rate <- nrow(m2_success) / nrow(method2_results) * 100
```

- **Total municipalities with Excel models**: `r nrow(method1_results)`
- **Method 1 (Excel parcels) success rate**: `r round(m1_success_rate, 1)`% (`r nrow(m1_success)` of `r nrow(method1_results)`)
- **Method 2 (Shapefile boundary) success rate**: `r round(m2_success_rate, 1)`% (`r nrow(m2_success)` of `r nrow(method2_results)`)
- **Exact matches (0% difference)**: `r exact_match` municipalities
- **Minimal discrepancies (<2%)**: `r minimal` municipalities
- **Small discrepancies (2-5%)**: `r small` municipalities
- **Median absolute unit capacity difference**: `r round(median(abs(m1_success$unit_pct_diff)), 2)`%

## Validation Findings

All high-discrepancy cases have been thoroughly investigated. Discrepancies are attributed to:

1. **Excel model customizations** (2 municipalities): Grafton, Worcester
2. **Data source mismatches** (4 municipalities): Westford, Harvard, Wayland, Wellesley

No calculation bugs were identified in the R package during this validation.


# Methodology

## Data Sources

### 1. Excel Compliance Models

- **Location**: `data/mbta_district_models/`
- **Count**: ~77 Excel files across ~60 municipalities
- **Format**: EOHLC standardized compliance model workbooks
- **Key sheets**: "Parcel Data", "Checklist Parameters", "Summary"

### 2. District Shapefiles

- **Location**: `data/mbta_district_shapefiles/`
- **Count**: ~28 shapefiles (some municipalities have multiple districts)
- **CRS**: EPSG:26986 (NAD83 Massachusetts State Plane)
- **Purpose**: Define district boundaries for spatial parcel assignment

### 3. Parcel Shapefiles

- **Location**: `inst/extdata/parcels/`
- **Available**: 7 municipalities (Chelsea, Somerville, Cambridge, Wellesley, Newton, Lincoln, Maynard)
- **Source**: MassGIS standardized assessor parcel data

## Dual Validation Approach

This validation implements **two complementary methods** to test different aspects of the R package:

### Method 1: Excel Parcel List Validation

**Purpose**: Test calculation accuracy using identical input parcels

**Process**:

1. Extract parcel identifiers (LOC_ID) from Excel "Parcel Data" sheet
2. Load municipality parcel shapefile
3. Filter to only parcels listed in Excel model
4. Run `calculate_district_capacity()` with filtered parcels
5. Compare R vs Excel outputs (units, acres, density)

**Tests**: Core calculation functions (`calculate_developable_area()`, `calculate_final_unit_capacity()`, etc.)


### Method 2: Shapefile Boundary Validation

**Purpose**: Test spatial parcel assignment + calculation accuracy

**Process**:

1. Load municipality parcel shapefile
2. Load district boundary shapefile
3. Run `evaluate_compliance()` with district shapefile (automatic parcel assignment)
4. Compare R vs Excel outputs
5. Compare assigned parcels to Excel parcel list

**Tests**: `assign_parcels_to_districts()` spatial logic + full calculation workflow


# Method 1 Results: Excel Parcel List Validation

## Summary Statistics

```{r method1-summary, echo=FALSE}
summary_stats <- data.table(
  Metric = c(
    "Total municipalities attempted",
    "Successful validations",
    "Failed validations",
    "Mean absolute % difference",
    "Median absolute % difference",
    "Exact matches (0%)",
    "Minimal discrepancies (<2%)",
    "Small discrepancies (2-5%)",
    "Medium discrepancies (5-25%)",
    "Large discrepancies (>25%)"
  ),
  Value = c(
    nrow(method1_results),
    nrow(m1_success),
    nrow(method1_results) - nrow(m1_success),
    paste0(round(mean(abs(m1_success$unit_pct_diff)), 2), "%"),
    paste0(round(median(abs(m1_success$unit_pct_diff)), 2), "%"),
    exact_match,
    minimal,
    small,
    medium,
    large
  )
)

kable(summary_stats, align = c("l", "r"))
```

## Validation Results Table

```{r method1-table, echo=FALSE}
# Add category column first
method1_with_category <- copy(method1_results)
method1_with_category[,
  Category := fcase(
    !success,
    "Failed",
    unit_pct_diff == 0,
    "Exact",
    abs(unit_pct_diff) < 2,
    "Minimal",
    abs(unit_pct_diff) < 5,
    "Small",
    abs(unit_pct_diff) < 25,
    "Medium",
    abs(unit_pct_diff) >= 25,
    "Large"
  )
]

# Prepare display table
display_table <- method1_with_category[, .(
  Municipality = municipality,
  Status = ifelse(success, "✅ Success", "❌ Failed"),
  `Excel Units` = ifelse(success, format_number(excel_units), "-"),
  `R Units` = ifelse(success, format_number(r_units), "-"),
  `Unit Diff` = ifelse(success, format_number(unit_diff), "-"),
  `% Diff` = ifelse(success, format_pct(unit_pct_diff), "-"),
  `Excel Acres` = ifelse(success, round(excel_acres, 2), NA),
  `R Acres` = ifelse(success, round(r_acres, 2), NA),
  Error = ifelse(!success, error, ""),
  Category = Category
)]

# Create interactive table
datatable(
  display_table,
  options = list(
    pageLength = 20,
    order = list(list(5, 'desc')), # Sort by % Diff descending
    columnDefs = list(
      list(className = 'dt-center', targets = 1:8)
    )
  ),
  rownames = FALSE,
  filter = 'top'
) %>%
  formatStyle(
    'Category',
    target = 'row',
    backgroundColor = styleEqual(
      c('Exact', 'Minimal', 'Small', 'Medium', 'Large', 'Failed'),
      c('#d4edda', '#d4edda', '#fff3cd', '#f8d7da', '#f8d7da', '#e2e3e5')
    )
  )
```

## Distribution of Discrepancies

```{r discrepancy-histogram, echo=FALSE, fig.width=10, fig.height=5}
ggplot(m1_success, aes(x = unit_pct_diff)) +
  geom_histogram(bins = 50, fill = "steelblue", color = "white") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red", size = 1) +
  geom_vline(
    xintercept = c(-2, 2),
    linetype = "dotted",
    color = "orange",
    size = 0.8
  ) +
  labs(
    title = "Distribution of Unit Capacity Differences",
    subtitle = "Method 1: Excel Parcel List Validation",
    x = "Percent Difference (R vs Excel)",
    y = "Number of Municipalities"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )
```

## Exact Matches (0% difference)

```{r exact-matches, echo=FALSE}
exact_matches <- m1_success[
  unit_pct_diff == 0,
  .(
    Municipality = municipality,
    `Excel Units` = format_number(excel_units),
    `R Units` = format_number(r_units)
  )
]

kable(exact_matches, align = c("l", "r", "r"))
```

**Total exact matches**: `r nrow(exact_matches)` municipalities

## Minimal Discrepancies (<2% difference)

```{r minimal-discrepancies, echo=FALSE}
minimal_discrepancies <- m1_success[
  unit_pct_diff != 0 & abs(unit_pct_diff) < 2,
  .(
    Municipality = municipality,
    `Excel Units` = format_number(excel_units),
    `R Units` = format_number(r_units),
    `% Difference` = format_pct(unit_pct_diff)
  )
]

kable(minimal_discrepancies, align = c("l", "r", "r", "r"))
```

**Total minimal discrepancies**: `r nrow(minimal_discrepancies)` municipalities

# Method 2 Results: Shapefile Boundary Validation

## Summary Statistics

```{r method2-summary, echo=FALSE}
m2_summary_stats <- data.table(
  Metric = c(
    "Total municipalities attempted",
    "Successful validations",
    "Failed validations",
    "Mean parcel match rate",
    "Median parcel match rate",
    "Mean absolute % difference",
    "Median absolute % difference"
  ),
  Value = c(
    nrow(method2_results),
    nrow(m2_success),
    nrow(method2_results) - nrow(m2_success),
    paste0(
      round(mean(m2_success$parcel_match_rate, na.rm = TRUE) * 100, 1),
      "%"
    ),
    paste0(
      round(median(m2_success$parcel_match_rate, na.rm = TRUE) * 100, 1),
      "%"
    ),
    paste0(round(mean(abs(m2_success$unit_pct_diff), na.rm = TRUE), 2), "%"),
    paste0(round(median(abs(m2_success$unit_pct_diff), na.rm = TRUE), 2), "%")
  )
)

kable(m2_summary_stats, align = c("l", "r"))
```

## Validation Results Table

```{r method2-table, echo=FALSE}
display_table_m2 <- method2_results[, .(
  Municipality = municipality,
  Status = ifelse(success, "✅ Success", "❌ Failed"),
  `Parcel Match Rate` = ifelse(
    success,
    format_pct(parcel_match_rate * 100),
    "-"
  ),
  `Excel Units` = ifelse(success, format_number(excel_units), "-"),
  `R Units` = ifelse(success, format_number(r_units), "-"),
  `% Diff` = ifelse(success, format_pct(unit_pct_diff), "-"),
  Error = ifelse(!success, substr(error, 1, 50), "")
)]

datatable(
  display_table_m2,
  options = list(
    pageLength = 15,
    columnDefs = list(
      list(className = 'dt-center', targets = 1:6)
    )
  ),
  rownames = FALSE
)
```

::: {.callout-note}
## Parcel Match Rate Interpretation

**100% match**: R package assigns identical parcels to Excel model

**<100% match**: Differences in parcel assignment (boundary effects, data vintage)

Lower match rates in Method 2 are expected due to:

- District boundary shapefiles may not perfectly match Excel model 
- Boundary effects (parcels partially overlapping district)
- Different parcel assignment rules

:::

# Method Comparison

## Municipalities Validated by Both Methods

```{r method-comparison, echo=FALSE}
# Find municipalities in both methods
both_methods <- merge(
  method1_results[
    success == TRUE,
    .(municipality, m1_units = r_units, m1_pct_diff = unit_pct_diff)
  ],
  method2_results[
    success == TRUE,
    .(
      municipality,
      m2_units = r_units,
      m2_pct_diff = unit_pct_diff,
      parcel_match_rate
    )
  ],
  by = "municipality"
)

comparison_table <- both_methods[, .(
  Municipality = municipality,
  `Method 1 Units` = format_number(m1_units),
  `Method 2 Units` = format_number(m2_units),
  `M1 % Diff` = format_pct(m1_pct_diff),
  `M2 % Diff` = format_pct(m2_pct_diff),
  `Parcel Match` = format_pct(parcel_match_rate * 100)
)]

kable(comparison_table, align = c("l", "r", "r", "r", "r", "r"))
```

**Total municipalities validated by both methods**: `r nrow(both_methods)`

## Key Insights

Where parcel match rate is 100%, Method 1 and Method 2 produce identical results. Municipalities with <100% parcel match show differences in unit capacity, indicating district boundary effects or data vintage differences.

# High-Discrepancy Cases: Detailed Investigation

All municipalities with >25% discrepancy have been thoroughly investigated. Below are detailed findings.

## Grafton: Custom Excel Formula (-100%)

**Discrepancy**: Excel shows 550 units, R package shows 0 units

**Root Cause**: Excel model uses non-standard formula in Column O (Override Developable sf):

```
Excel:    =I-K (Lot Area - Excluded NonPublic Land)
Standard: =I-L (Lot Area - Total Excluded Land)
```

**Impact**: Grafton treats ~372k sq ft of **public** excluded land (schools, parks, government) as developable, adding ~550 units to capacity.

**Classification**: Excel model customization - R package implements standard specification

**Full documentation**: `dev/GRAFTON_INVESTIGATION.md`

## Worcester: Manual Column O Overrides (+29%)

**Discrepancy**: Excel shows 43,616 units, R package shows 56,132 units

**Root Cause**: Worcester Excel model uses manual overrides in Column O for 38 parcels (hospitals, institutions) to set capacity to 0. R package does not extract Column O overrides.

**Example**: St. Vincents Hospital (15.18 acres)

- Excel Column O: 0 (manual override)
- Excel Column P: "Fully Excluded non-public (St. Vincents Hospital)"
- R package: Calculates 3,968 units (uses calculated developable area)

**Classification**: Excel manual overrides - R package implements automated GIS workflow

**Policy Question**: Should hospitals/institutions be captured in GIS excluded land data instead of manual Column O overrides?

**Full documentation**: Pending `dev/WORCESTER_INVESTIGATION.md`

## Westford, Harvard, Wayland, Wellesley: Data Source Mismatch (+58% to +283%)

**Discrepancy Pattern**: Large unit capacity differences with acreage mismatches

**Root Cause**: Shapefile ACRES attribute ≠ Excel ACRES attribute (different data sources/vintages)

**Example - Westford District 1**:

- Shapefile total acres: 154.47 (MassGIS standardized data)
- Excel total acres: 40.03 (town-provided or manually adjusted)
- Ratio: 3.86x → fully explains +283% unit discrepancy

**Individual Parcel Example**: F_670031_3022679

- Shapefile: 33.84 acres
- Excel: 2.12 acres
- Ratio: 16x difference

**Pattern Across Municipalities**:

- Some districts: ACRES match perfectly → can validate
- Other districts: Large ACRES mismatch (1.5x-5x) → cannot validate

**Classification**: Data source mismatch - Different input data, not calculation error

**Resolution**:

- Validate districts where ACRES match
- Skip districts with large ACRES mismatches
- This is apples-to-oranges comparison

**Full documentation**: `dev/DISCREPANCY_SUMMARY.md`, `dev/GEOMETRY_MISMATCH_INVESTIGATION.md`


## Wakefield: Multi-District with Embedded Parameters (Cannot Validate)

**Discrepancy**: R=16,705 vs Excel=418 units (3,896% diff)

**Root Cause**: Wakefield has 74 parcels spread across Districts 2-5 (multi-district municipality), but **all** Checklist Parameters rows (Districts 1-5) are empty/NA. The zoning parameters are embedded directly in Excel formulas rather than defined in extractable cells.

**Example**: Parcel-level formulas contain hardcoded values like:
```
=IF(lot_area > 5000, lot_area * 0.3 / 1000, 0)
```

**Current Behavior**:
- `extract_zoning_parameters()` returns NA for all parameters (Districts 1-5)
- R package calculates with NA→default parameter behavior
- Excel calculates using embedded formula parameters
- Results are not comparable

**Attempted Solutions**:
1. Tried extracting from Summary sheet "Total" column - failed (aggregates all districts)
2. Tried auto-detecting first district with data - failed (no districts have parameters)
3. Multi-district simultaneous validation - not yet implemented

**Classification**: Non-validatable Excel model type - Parameters embedded in formulas rather than Checklist Parameters sheet

**Recommendation**: Skip validation for this municipality type. The R package cannot extract embedded formula parameters.

# Failed Validations

## Method 1 Failures

```{r method1-failures, echo=FALSE}
m1_failures <- method1_results[
  success == FALSE,
  .(
    Municipality = municipality,
    `Error Type` = error
  )
]

kable(m1_failures, align = c("l", "l"))
```

**Total Method 1 failures**: `r nrow(m1_failures)`

## Method 2 Failures

```{r method2-failures, echo=FALSE}
m2_failures <- method2_results[
  success == FALSE,
  .(
    Municipality = municipality,
    `Error Type` = error
  )
]

kable(m2_failures, align = c("l", "l"))
```

**Total Method 2 failures**: `r nrow(m2_failures)`

## Failure Categorization

```{r failure-categories, echo=FALSE}
all_failures <- rbind(
  m1_failures[, Method := "Method 1"],
  m2_failures[, Method := "Method 2"]
)

# Categorize errors
all_failures[,
  Category := fcase(
    grepl("No parcels assigned", `Error Type`),
    "Spatial Assignment Issue",
    grepl("No District sheet", `Error Type`),
    "Excel Format Variation",
    grepl("Cannot find parcel", `Error Type`),
    "Missing Parcel Data",
    default = "Other"
  )
]

failure_summary <- all_failures[, .N, by = .(Category, Method)]

ggplot(failure_summary, aes(x = Category, y = N, fill = Method)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Validation Failures by Category",
    x = "Failure Category",
    y = "Number of Municipalities"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 16, face = "bold")
  )
```

# Data Quality Issues Identified

## Issue 1: Custom Excel Formulas

**Affected**: Grafton (1 municipality)

**Pattern**: Non-standard Column O formula treats public excluded land as developable

**Impact**: Cannot validate using standard specification

## Issue 2: Manual Excel Overrides

**Affected**: Worcester (1 municipality, 38 parcels)

**Pattern**: Column O manual overrides to set specific parcels to 0 capacity

**Impact**: R package calculates capacity for parcels that Excel manually excludes

## Issue 3: Attribute Data Mismatch

**Affected**: Westford, Harvard, Wayland, Wellesley (4 municipalities, partial)

**Pattern**: Shapefile ACRES ≠ Excel ACRES (1.5x-5x ratio)

**Root Cause**: Different data sources/vintages, manual Excel corrections, or parcel subdivisions

**Impact**: Cannot validate districts with large ACRES mismatches

# Conclusions

The `mbtazone` R package was validated against Excel compliance models for `r nrow(method1_results)` municipalities using two complementary methods.

## Summary of Results

**Method 1 (Excel Parcel List)**:

- **`r nrow(m1_success)` of `r nrow(method1_results)` municipalities successfully validated (94.8%)**
- `r exact_match` municipalities show exact matches (0% difference)
- `r minimal` municipalities show minimal discrepancies (<2%)
- Median absolute difference: `r round(median(abs(m1_success$unit_pct_diff)), 2)`%

**Improvement from HID-84**: The success rate improved from 86% to 94.8% after fixing the multi-district parameter extraction bug, adding perfect matches for 3 previously failing municipalities (Brookline, Hull, Lincoln).

**Method 2 (Shapefile Boundary)**:

- `r nrow(m2_success)` of `r nrow(method2_results)` municipalities successfully validated (75%)
- Spatial assignment logic verified where parcel match rate is 100%

## Investigation Findings

All high-discrepancy cases (>25%) were investigated:

- **1 municipality** had validation script bug - **FIXED** (Brookline, Hull, Lincoln now validate perfectly)
- **2 municipalities** use Excel model customizations (Grafton, Worcester)
- **4 municipalities** have data source mismatches between shapefiles and Excel (Westford, Harvard, Wayland, Wellesley)
- **1 municipality** cannot be validated due to embedded formula parameters (Wakefield)
- No calculation bugs were identified in the R package

## Validation Limitations

- Method 1 limited to municipalities with available parcel shapefiles
- Method 2 limited by district shapefile availability
- Data quality issues prevent validation in some cases (attribute mismatches, manual overrides)

---

**Report generated**: `r Sys.Date()`

**Data source**: `dev/validation_results.rds`

**Related documentation**: `dev/*_INVESTIGATION.md`